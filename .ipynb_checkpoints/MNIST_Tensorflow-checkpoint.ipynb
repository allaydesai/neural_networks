{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded.\n"
     ]
    }
   ],
   "source": [
    "def download(url, file):\n",
    "    \"\"\"\n",
    "    Download file from <url>\n",
    "    :param url: URL to file\n",
    "    :param file: Local file path\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "\n",
    "# Download the training and test dataset.\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_train.zip', 'notMNIST_train.zip')\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_test.zip', 'notMNIST_test.zip')\n",
    "\n",
    "# Make sure the files aren't corrupted\n",
    "assert hashlib.md5(open('notMNIST_train.zip', 'rb').read()).hexdigest() == 'c8673b3f28f489e9cdf3a3d74e2ac8fa',\\\n",
    "        'notMNIST_train.zip file is corrupted.  Remove the file and try again.'\n",
    "assert hashlib.md5(open('notMNIST_test.zip', 'rb').read()).hexdigest() == '5d3c7e653e63471c88df796156a9dfa9',\\\n",
    "        'notMNIST_test.zip file is corrupted.  Remove the file and try again.'\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('All files downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 210001/210001 [00:52<00:00, 3986.92files/s]\n",
      "100%|███████████████████████████████████████| 10001/10001 [00:03<00:00, 3222.81files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features and labels uncompressed.\n"
     ]
    }
   ],
   "source": [
    "def uncompress_features_labels(file):\n",
    "    \"\"\"\n",
    "    Uncompress features and labels from a zip file\n",
    "    :param file: The zip file to extract the data from\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with ZipFile(file) as zipf:\n",
    "        # Progress Bar\n",
    "        filenames_pbar = tqdm(zipf.namelist(), unit='files')\n",
    "        \n",
    "        # Get features and labels from all files\n",
    "        for filename in filenames_pbar:\n",
    "            # Check if the file is a directory\n",
    "            if not filename.endswith('/'):\n",
    "                with zipf.open(filename) as image_file:\n",
    "                    image = Image.open(image_file)\n",
    "                    image.load()\n",
    "                    # Load image data as 1 dimensional array\n",
    "                    # We're using float32 to save on memory space\n",
    "                    feature = np.array(image, dtype=np.float32).flatten()\n",
    "\n",
    "                # Get the the letter from the filename.  This is the letter of the image.\n",
    "                label = os.path.split(filename)[1][0]\n",
    "\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Get the features and labels from the zip files\n",
    "train_features, train_labels = uncompress_features_labels('notMNIST_train.zip')\n",
    "test_features, test_labels = uncompress_features_labels('notMNIST_test.zip')\n",
    "\n",
    "# Limit the amount of data to work with a docker container\n",
    "docker_size_limit = 150000 #500,000 training images\n",
    "train_features, train_labels = resample(train_features, train_labels, n_samples=docker_size_limit)\n",
    "\n",
    "# Set flags for feature engineering.  This will prevent you from skipping an important step.\n",
    "is_features_normal = False\n",
    "is_labels_encod = False\n",
    "\n",
    "# Wait until you see that all features and labels have been uncompressed.\n",
    "print('All features and labels uncompressed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features (150000, 784)\n",
      "Training Image (784,)\n",
      "train_labels (150000,)\n",
      "Label:  B\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFOEHgiL8QFCEHwiK8ANB/T/dK0TzfMgk7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aaecab8c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"train_features\", train_features.shape)\n",
    "print(\"Training Image\", train_features[0].shape)\n",
    "print(\"train_labels\", train_labels.shape)\n",
    "print(\"Label: \", train_labels[0])\n",
    "plt.imshow(np.array(train_features[0].reshape((28,28))),cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groom the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    Xmin = np.min(image_data) #0\n",
    "    Xmax = np.max(image_data) #255\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    #print(\"Xmin:\", Xmin, \"Xmax:\", Xmax)\n",
    "    return a + (((image_data-Xmin)*(b-a))/(Xmax- Xmin))\n",
    "\n",
    "if not is_features_normal:\n",
    "    train_features = normalize_grayscale(train_features)\n",
    "    test_features = normalize_grayscale(test_features)\n",
    "    is_features_normal = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not is_labels_encod:\n",
    "    # Turn labels into numbers and apply One-Hot Encoding\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(train_labels)\n",
    "    train_labels = encoder.transform(train_labels)\n",
    "    test_labels = encoder.transform(test_labels)\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    train_labels = train_labels.astype(np.float32)\n",
    "    test_labels = test_labels.astype(np.float32)\n",
    "    is_labels_encod = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert is_features_normal, 'You skipped the step to normalize the features'\n",
    "assert is_labels_encod, 'You skipped the step to One-Hot Encode the labels'\n",
    "\n",
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "print('Training features and labels randomized and split.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the data for easy access\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('notMNIST.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': train_features,\n",
    "                    'train_labels': train_labels,\n",
    "                    'valid_dataset': valid_features,\n",
    "                    'valid_labels': valid_labels,\n",
    "                    'test_dataset': test_features,\n",
    "                    'test_labels': test_labels,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload the data\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  train_features = pickle_data['train_dataset']\n",
    "  train_labels = pickle_data['train_labels']\n",
    "  valid_features = pickle_data['valid_dataset']\n",
    "  valid_labels = pickle_data['valid_labels']\n",
    "  test_features = pickle_data['test_dataset']\n",
    "  test_labels = pickle_data['test_labels']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "\n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Dataset Stats\")\n",
    "print(\"train_features: \", train_features.shape)\n",
    "print(\"valid_features: \", valid_features.shape)\n",
    "print(\"test_features: \", test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 -Loss: 64258.9570 Validation Accuracy: 0.085938\n",
      "Epoch  1, Batch   2 -Loss: 51398.9727 Validation Accuracy: 0.101562\n",
      "Epoch  1, Batch   3 -Loss: 44075.4062 Validation Accuracy: 0.101562\n",
      "Epoch  1, Batch   4 -Loss: 38978.5117 Validation Accuracy: 0.101562\n",
      "Epoch  1, Batch   5 -Loss: 28400.0605 Validation Accuracy: 0.097656\n",
      "Epoch  1, Batch   6 -Loss: 24293.8535 Validation Accuracy: 0.136719\n",
      "Epoch  1, Batch   7 -Loss: 25216.8750 Validation Accuracy: 0.144531\n",
      "Epoch  1, Batch   8 -Loss: 23023.1562 Validation Accuracy: 0.125000\n",
      "Epoch  1, Batch   9 -Loss: 16957.4980 Validation Accuracy: 0.144531\n",
      "Epoch  1, Batch  10 -Loss: 20262.4805 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch  11 -Loss: 21633.7500 Validation Accuracy: 0.179688\n",
      "Epoch  1, Batch  12 -Loss: 18296.3145 Validation Accuracy: 0.187500\n",
      "Epoch  1, Batch  13 -Loss: 15902.8018 Validation Accuracy: 0.195312\n",
      "Epoch  1, Batch  14 -Loss: 17379.4219 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch  15 -Loss: 17678.4121 Validation Accuracy: 0.207031\n",
      "Epoch  1, Batch  16 -Loss: 14915.3594 Validation Accuracy: 0.218750\n",
      "Epoch  1, Batch  17 -Loss: 10653.6035 Validation Accuracy: 0.222656\n",
      "Epoch  1, Batch  18 -Loss: 14795.7676 Validation Accuracy: 0.218750\n",
      "Epoch  1, Batch  19 -Loss: 13612.8398 Validation Accuracy: 0.218750\n",
      "Epoch  1, Batch  20 -Loss: 14469.2422 Validation Accuracy: 0.230469\n",
      "Epoch  1, Batch  21 -Loss: 14379.0664 Validation Accuracy: 0.257812\n",
      "Epoch  1, Batch  22 -Loss: 14375.0781 Validation Accuracy: 0.246094\n",
      "Epoch  1, Batch  23 -Loss: 14348.7021 Validation Accuracy: 0.246094\n",
      "Epoch  1, Batch  24 -Loss: 12428.9600 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  25 -Loss: 14170.0762 Validation Accuracy: 0.273438\n",
      "Epoch  1, Batch  26 -Loss: 11831.0635 Validation Accuracy: 0.292969\n",
      "Epoch  1, Batch  27 -Loss: 13371.6396 Validation Accuracy: 0.292969\n",
      "Epoch  1, Batch  28 -Loss: 11034.5840 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  29 -Loss: 10405.4863 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  30 -Loss:  9827.7441 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  31 -Loss: 11387.0801 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  32 -Loss: 11371.6016 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  33 -Loss: 11467.6416 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  34 -Loss: 10397.8750 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  35 -Loss: 10999.3447 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  36 -Loss: 10824.6494 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  37 -Loss: 11527.9316 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  38 -Loss: 10627.8721 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  39 -Loss:  9934.7891 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  40 -Loss: 10495.5381 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  41 -Loss:  8846.3086 Validation Accuracy: 0.367188\n",
      "Epoch  1, Batch  42 -Loss:  8238.2373 Validation Accuracy: 0.363281\n",
      "Epoch  1, Batch  43 -Loss:  9068.0352 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  44 -Loss:  8554.2598 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  45 -Loss:  8743.0684 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  46 -Loss:  8506.1846 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  47 -Loss:  8732.1777 Validation Accuracy: 0.390625\n",
      "Epoch  1, Batch  48 -Loss: 10812.7832 Validation Accuracy: 0.382812\n",
      "Epoch  1, Batch  49 -Loss:  7904.7695 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  50 -Loss:  8889.7285 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  51 -Loss:  8357.7061 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  52 -Loss:  9856.2832 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  53 -Loss:  8148.7012 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  54 -Loss:  9079.0020 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  55 -Loss:  6141.3042 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  56 -Loss:  8965.4990 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  57 -Loss:  8266.0723 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  58 -Loss:  6711.7305 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  59 -Loss:  6946.7734 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  60 -Loss:  5419.1729 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  61 -Loss:  8215.6562 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  62 -Loss:  7354.5146 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  63 -Loss:  8147.3696 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  64 -Loss:  6466.5859 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  65 -Loss:  7391.5381 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  66 -Loss:  5694.0479 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  67 -Loss:  7791.4102 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  68 -Loss:  6834.2441 Validation Accuracy: 0.453125\n",
      "Epoch  1, Batch  69 -Loss:  6529.9116 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  70 -Loss:  6004.5410 Validation Accuracy: 0.464844\n",
      "Epoch  1, Batch  71 -Loss:  6196.4443 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  72 -Loss:  7396.8286 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  73 -Loss:  6569.8994 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  74 -Loss:  5602.3525 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  75 -Loss:  5329.2334 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  76 -Loss:  7427.1694 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  77 -Loss:  6272.4551 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  78 -Loss:  8822.7979 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  79 -Loss:  6665.3682 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  80 -Loss:  4688.6362 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  81 -Loss:  6037.7217 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  82 -Loss:  6761.2646 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  83 -Loss:  5146.2114 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  84 -Loss:  6160.2285 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  85 -Loss:  6317.8457 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  86 -Loss:  4776.3188 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  87 -Loss:  6671.0205 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  88 -Loss:  6071.4058 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  89 -Loss:  5200.5054 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  90 -Loss:  5592.7266 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  91 -Loss:  4947.9229 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  92 -Loss:  5376.1143 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  93 -Loss:  5581.4600 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  94 -Loss:  4768.9600 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  95 -Loss:  5129.0806 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  96 -Loss:  5340.2275 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  97 -Loss:  4966.8711 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  98 -Loss:  5730.7354 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  99 -Loss:  5513.0811 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch 100 -Loss:  3955.4243 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch 101 -Loss:  4086.6721 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch 102 -Loss:  4292.1973 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch 103 -Loss:  4150.5967 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch 104 -Loss:  4625.3857 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch 105 -Loss:  6056.0908 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch 106 -Loss:  4549.2021 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch 107 -Loss:  5604.7646 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch 108 -Loss:  4652.2378 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch 109 -Loss:  5485.0693 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 110 -Loss:  4632.6758 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch 111 -Loss:  5381.8442 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch 112 -Loss:  6514.3848 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 113 -Loss:  3841.9634 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 114 -Loss:  5168.5127 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch 115 -Loss:  4158.5991 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 116 -Loss:  4079.7246 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch 117 -Loss:  3948.1660 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch 118 -Loss:  3710.5850 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 119 -Loss:  4495.0244 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch 120 -Loss:  4428.3340 Validation Accuracy: 0.527344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 121 -Loss:  4427.2637 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch 122 -Loss:  4866.3457 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 123 -Loss:  4664.1338 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 124 -Loss:  3936.7139 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch 125 -Loss:  3508.3120 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 126 -Loss:  4748.4810 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 127 -Loss:  4706.6367 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 128 -Loss:  5295.4375 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch 129 -Loss:  4703.8086 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 130 -Loss:  4106.0088 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 131 -Loss:  4861.0015 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 132 -Loss:  4479.1138 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch 133 -Loss:  4771.9673 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 134 -Loss:  3687.7017 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 135 -Loss:  5715.6021 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch 136 -Loss:  4648.8501 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch 137 -Loss:  4262.1992 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 138 -Loss:  3946.8298 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 139 -Loss:  3308.4280 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 140 -Loss:  3627.0146 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 141 -Loss:  4243.3970 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 142 -Loss:  2862.1982 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 143 -Loss:  4111.3994 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 144 -Loss:  3877.6846 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 145 -Loss:  3166.4302 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 146 -Loss:  4319.0020 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 147 -Loss:  3141.3657 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 148 -Loss:  4357.7021 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 149 -Loss:  3856.5730 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 150 -Loss:  4157.6768 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 151 -Loss:  4446.2168 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 152 -Loss:  3869.6924 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 153 -Loss:  4660.7554 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 154 -Loss:  3189.9834 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 155 -Loss:  3935.5195 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 156 -Loss:  3235.3523 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 157 -Loss:  3976.3416 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 158 -Loss:  3857.7429 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 159 -Loss:  3735.9607 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 160 -Loss:  3032.5237 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 161 -Loss:  3325.7810 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 162 -Loss:  3403.0583 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 163 -Loss:  2676.1226 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 164 -Loss:  3201.7065 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 165 -Loss:  3803.9854 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 166 -Loss:  3243.7593 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 167 -Loss:  2878.0457 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 168 -Loss:  3202.1509 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 169 -Loss:  4437.7051 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 170 -Loss:  3459.8745 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 171 -Loss:  3428.0244 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 172 -Loss:  3015.5190 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 173 -Loss:  3578.5635 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 174 -Loss:  2430.3848 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 175 -Loss:  3591.0891 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 176 -Loss:  2528.5210 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 177 -Loss:  3198.7312 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 178 -Loss:  3046.3008 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 179 -Loss:  3937.6880 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 180 -Loss:  2527.9963 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 181 -Loss:  3244.7412 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 182 -Loss:  3866.6667 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 183 -Loss:  2790.2021 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 184 -Loss:  3471.9512 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 185 -Loss:  4453.4614 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 186 -Loss:  3985.4734 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 187 -Loss:  2411.9270 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 188 -Loss:  2739.4844 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 189 -Loss:  3152.8567 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 190 -Loss:  2122.9814 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 191 -Loss:  2738.8071 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 192 -Loss:  2250.4863 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 193 -Loss:  2373.8804 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 194 -Loss:  3121.6489 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 195 -Loss:  2523.5400 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 196 -Loss:  3051.4033 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 197 -Loss:  2964.2683 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 198 -Loss:  3049.1311 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 199 -Loss:  2951.0642 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 200 -Loss:  2840.1812 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 201 -Loss:  3490.2178 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 202 -Loss:  3032.4287 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 203 -Loss:  2392.5918 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 204 -Loss:  2278.0854 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 205 -Loss:  2767.9656 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 206 -Loss:  2866.4875 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 207 -Loss:  2422.6792 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 208 -Loss:  2586.9246 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 209 -Loss:  2988.7625 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 210 -Loss:  2440.5122 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 211 -Loss:  2866.3345 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 212 -Loss:  3913.6938 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 213 -Loss:  3472.8140 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 214 -Loss:  2891.2490 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 215 -Loss:  2691.1230 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 216 -Loss:  2694.7607 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 217 -Loss:  2429.0923 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 218 -Loss:  1909.6333 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 219 -Loss:  2200.7847 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 220 -Loss:  2322.9546 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 221 -Loss:  3120.3027 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 222 -Loss:  2872.9053 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 223 -Loss:  2900.0864 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 224 -Loss:  2579.9404 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 225 -Loss:  2259.8086 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 226 -Loss:  3154.7700 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 227 -Loss:  2920.5291 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 228 -Loss:  2766.2876 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 229 -Loss:  3637.1147 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 230 -Loss:  2524.4492 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 231 -Loss:  2636.6821 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 232 -Loss:  1866.6277 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 233 -Loss:  2802.3186 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 234 -Loss:  2133.7524 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 235 -Loss:  2458.2812 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 236 -Loss:  2027.9841 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 237 -Loss:  2693.1304 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 238 -Loss:  1371.6699 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 239 -Loss:  2396.1880 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 240 -Loss:  2801.2468 Validation Accuracy: 0.613281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 241 -Loss:  2659.5190 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 242 -Loss:  3379.1440 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 243 -Loss:  2123.9038 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 244 -Loss:  2597.9814 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 245 -Loss:  2124.0442 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 246 -Loss:  2475.9719 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 247 -Loss:  1913.5365 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 248 -Loss:  2723.7341 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 249 -Loss:  2387.4260 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 250 -Loss:  2698.3276 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 251 -Loss:  2547.8794 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 252 -Loss:  2333.2891 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 253 -Loss:  2263.9622 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 254 -Loss:  2537.5671 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 255 -Loss:  2279.8071 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 256 -Loss:  2378.0156 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 257 -Loss:  2774.4136 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 258 -Loss:  2193.8904 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 259 -Loss:  2521.4685 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 260 -Loss:  2339.7427 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 261 -Loss:  2432.8018 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 262 -Loss:  2207.3071 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 263 -Loss:  2354.5125 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 264 -Loss:  2575.5430 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 265 -Loss:  2495.2417 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 266 -Loss:  2253.3755 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 267 -Loss:  2287.1855 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 268 -Loss:  2390.0532 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 269 -Loss:  2010.7732 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 270 -Loss:  1884.0602 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 271 -Loss:  1751.9976 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 272 -Loss:  2518.6655 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 273 -Loss:  1974.7600 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 274 -Loss:  2161.0061 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 275 -Loss:  1742.5791 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 276 -Loss:  2675.7842 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 277 -Loss:  2367.4575 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 278 -Loss:  2941.6946 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 279 -Loss:  1911.6321 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 280 -Loss:  2396.9946 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 281 -Loss:  2217.6660 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 282 -Loss:  2103.1648 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 283 -Loss:  2393.1150 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 284 -Loss:  2275.2043 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 285 -Loss:  1867.3971 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 286 -Loss:  1831.6458 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 287 -Loss:  1582.1443 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 288 -Loss:  1759.1514 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 289 -Loss:  1851.0681 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 290 -Loss:  2176.9260 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 291 -Loss:  1799.9373 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 292 -Loss:  2849.2212 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 293 -Loss:  1710.3163 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 294 -Loss:  2477.0007 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 295 -Loss:  1821.1592 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 296 -Loss:  2668.2390 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 297 -Loss:  2759.8765 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 298 -Loss:  1799.8740 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 299 -Loss:  1155.8273 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 300 -Loss:  1651.2549 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 301 -Loss:  2189.2173 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 302 -Loss:  2447.5645 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 303 -Loss:  1084.4602 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 304 -Loss:  1965.5632 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 305 -Loss:  2281.4790 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 306 -Loss:  1948.7346 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 307 -Loss:  2176.4336 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 308 -Loss:  1923.7297 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 309 -Loss:  2088.8877 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 310 -Loss:  2202.4651 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 311 -Loss:  2166.1201 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 312 -Loss:  1743.9351 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 313 -Loss:  2341.6528 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 314 -Loss:  1154.5312 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 315 -Loss:  1430.3289 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 316 -Loss:  1846.4818 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 317 -Loss:  1458.0515 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 318 -Loss:  1410.6472 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 319 -Loss:  2058.8232 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 320 -Loss:  1862.0037 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 321 -Loss:  1948.5856 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 322 -Loss:  2099.6709 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 323 -Loss:  2599.3555 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 324 -Loss:  1764.8574 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 325 -Loss:  1780.1339 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 326 -Loss:  1816.2106 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 327 -Loss:  1627.1509 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 328 -Loss:  1927.4534 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 329 -Loss:  2061.7715 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 330 -Loss:  2524.0586 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 331 -Loss:  2090.3862 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 332 -Loss:  2387.2085 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 333 -Loss:  2451.5754 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 334 -Loss:  1880.9431 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 335 -Loss:  2516.6492 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 336 -Loss:  2509.9050 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 337 -Loss:  1270.7338 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 338 -Loss:  1775.6760 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 339 -Loss:  1470.2229 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 340 -Loss:  1673.4364 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 341 -Loss:  1714.1152 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 342 -Loss:  2527.1182 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 343 -Loss:  1974.0466 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 344 -Loss:  2228.5703 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 345 -Loss:  1751.7495 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 346 -Loss:  1897.4197 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 347 -Loss:  1506.6821 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 348 -Loss:  1851.4810 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 349 -Loss:  2381.5459 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 350 -Loss:  1719.9276 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 351 -Loss:  1821.8455 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 352 -Loss:  1415.0181 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 353 -Loss:  2071.7922 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 354 -Loss:  1852.9368 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 355 -Loss:  1366.1034 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 356 -Loss:  1621.4146 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 357 -Loss:  2266.6228 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 358 -Loss:  1653.2468 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 359 -Loss:  1734.3193 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 360 -Loss:  2203.2478 Validation Accuracy: 0.656250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 361 -Loss:  1660.4822 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 362 -Loss:  1554.2012 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 363 -Loss:  1912.5837 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 364 -Loss:  1595.9197 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 365 -Loss:  2575.8599 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 366 -Loss:  2062.4253 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 367 -Loss:  1995.1512 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 368 -Loss:  1623.2314 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 369 -Loss:  1966.7991 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 370 -Loss:  2340.6909 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 371 -Loss:  1860.9894 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 372 -Loss:  1748.0913 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 373 -Loss:  1688.3059 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 374 -Loss:  1900.0217 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 375 -Loss:  1151.8041 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 376 -Loss:  1514.4048 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 377 -Loss:  1604.5060 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 378 -Loss:  1825.6704 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 379 -Loss:  2101.7070 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 380 -Loss:  2116.0776 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 381 -Loss:  1646.6069 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 382 -Loss:  1584.8365 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 383 -Loss:  1308.0989 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 384 -Loss:  1562.8271 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 385 -Loss:  1058.0697 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 386 -Loss:  2370.4590 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 387 -Loss:  1818.4467 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 388 -Loss:  1453.0364 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 389 -Loss:  1747.4158 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 390 -Loss:  1542.3374 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 391 -Loss:  1924.8361 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 392 -Loss:  1589.1754 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 393 -Loss:  1792.4255 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 394 -Loss:  1709.9739 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 395 -Loss:  1915.6973 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 396 -Loss:  1616.7869 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 397 -Loss:  2030.6438 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 398 -Loss:  1822.3109 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 399 -Loss:  2034.8098 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 400 -Loss:  1325.5486 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 401 -Loss:  1962.9978 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 402 -Loss:  1374.8872 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 403 -Loss:  1439.2434 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 404 -Loss:  1983.2122 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 405 -Loss:  1959.5421 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 406 -Loss:  1719.5913 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 407 -Loss:  1007.5022 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 408 -Loss:  1302.6160 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 409 -Loss:  1290.3171 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 410 -Loss:  2275.3262 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 411 -Loss:  1264.9180 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 412 -Loss:  1831.7170 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 413 -Loss:  1641.4966 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 414 -Loss:  1752.0205 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 415 -Loss:  1642.0273 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 416 -Loss:  1261.4948 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 417 -Loss:  1471.8669 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 418 -Loss:  1108.7603 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 419 -Loss:  1269.4011 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 420 -Loss:  1965.6655 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 421 -Loss:  1767.1729 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 422 -Loss:  1617.2579 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 423 -Loss:  1676.4248 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 424 -Loss:  1679.8176 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 425 -Loss:  2177.1348 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 426 -Loss:  1552.8076 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 427 -Loss:  1703.4397 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 428 -Loss:  1389.4077 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 429 -Loss:  1300.1453 Validation Accuracy: 0.667969\n",
      "Epoch  2, Batch   1 -Loss:  1741.6528 Validation Accuracy: 0.671875\n",
      "Epoch  2, Batch   2 -Loss:  1443.8345 Validation Accuracy: 0.660156\n",
      "Epoch  2, Batch   3 -Loss:  1703.0121 Validation Accuracy: 0.664062\n",
      "Epoch  2, Batch   4 -Loss:  1117.9036 Validation Accuracy: 0.664062\n",
      "Epoch  2, Batch   5 -Loss:  1353.9099 Validation Accuracy: 0.664062\n",
      "Epoch  2, Batch   6 -Loss:  1788.9276 Validation Accuracy: 0.664062\n",
      "Epoch  2, Batch   7 -Loss:  1538.7898 Validation Accuracy: 0.664062\n",
      "Epoch  2, Batch   8 -Loss:  1343.4417 Validation Accuracy: 0.664062\n",
      "Epoch  2, Batch   9 -Loss:  1804.8994 Validation Accuracy: 0.656250\n",
      "Epoch  2, Batch  10 -Loss:  1769.4860 Validation Accuracy: 0.660156\n",
      "Epoch  2, Batch  11 -Loss:  1347.2228 Validation Accuracy: 0.664062\n",
      "Epoch  2, Batch  12 -Loss:  1836.9238 Validation Accuracy: 0.656250\n",
      "Epoch  2, Batch  13 -Loss:  1024.5063 Validation Accuracy: 0.656250\n",
      "Epoch  2, Batch  14 -Loss:  1594.3588 Validation Accuracy: 0.667969\n",
      "Epoch  2, Batch  15 -Loss:  1267.9329 Validation Accuracy: 0.671875\n",
      "Epoch  2, Batch  16 -Loss:  1624.4275 Validation Accuracy: 0.683594\n",
      "Epoch  2, Batch  17 -Loss:  1735.0857 Validation Accuracy: 0.683594\n",
      "Epoch  2, Batch  18 -Loss:  2076.6414 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  19 -Loss:  1629.0015 Validation Accuracy: 0.679688\n",
      "Epoch  2, Batch  20 -Loss:  1437.2449 Validation Accuracy: 0.675781\n",
      "Epoch  2, Batch  21 -Loss:  1620.2087 Validation Accuracy: 0.675781\n",
      "Epoch  2, Batch  22 -Loss:  1707.7804 Validation Accuracy: 0.687500\n",
      "Epoch  2, Batch  23 -Loss:  1424.1799 Validation Accuracy: 0.687500\n",
      "Epoch  2, Batch  24 -Loss:  1143.2802 Validation Accuracy: 0.687500\n",
      "Epoch  2, Batch  25 -Loss:  1100.4590 Validation Accuracy: 0.687500\n",
      "Epoch  2, Batch  26 -Loss:  1452.5267 Validation Accuracy: 0.687500\n",
      "Epoch  2, Batch  27 -Loss:  1540.4346 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  28 -Loss:  1780.1294 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  29 -Loss:  1463.3385 Validation Accuracy: 0.687500\n",
      "Epoch  2, Batch  30 -Loss:  1998.8925 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  31 -Loss:  1642.9939 Validation Accuracy: 0.683594\n",
      "Epoch  2, Batch  32 -Loss:  1630.0610 Validation Accuracy: 0.679688\n",
      "Epoch  2, Batch  33 -Loss:  1259.3384 Validation Accuracy: 0.679688\n",
      "Epoch  2, Batch  34 -Loss:  1518.0299 Validation Accuracy: 0.679688\n",
      "Epoch  2, Batch  35 -Loss:   974.2448 Validation Accuracy: 0.683594\n",
      "Epoch  2, Batch  36 -Loss:  1748.2649 Validation Accuracy: 0.683594\n",
      "Epoch  2, Batch  37 -Loss:  1290.7878 Validation Accuracy: 0.675781\n",
      "Epoch  2, Batch  38 -Loss:  1926.9199 Validation Accuracy: 0.671875\n",
      "Epoch  2, Batch  39 -Loss:  1237.3832 Validation Accuracy: 0.675781\n",
      "Epoch  2, Batch  40 -Loss:  1370.6924 Validation Accuracy: 0.671875\n",
      "Epoch  2, Batch  41 -Loss:  1453.9919 Validation Accuracy: 0.667969\n",
      "Epoch  2, Batch  42 -Loss:  1658.5049 Validation Accuracy: 0.679688\n",
      "Epoch  2, Batch  43 -Loss:  1093.7480 Validation Accuracy: 0.683594\n",
      "Epoch  2, Batch  44 -Loss:  1387.9127 Validation Accuracy: 0.679688\n",
      "Epoch  2, Batch  45 -Loss:  1308.0791 Validation Accuracy: 0.687500\n",
      "Epoch  2, Batch  46 -Loss:  1363.1312 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  47 -Loss:   967.0881 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  48 -Loss:  1189.8699 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  49 -Loss:  1435.6888 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  50 -Loss:  1280.3204 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  51 -Loss:  1265.3086 Validation Accuracy: 0.699219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch  52 -Loss:  1440.1780 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  53 -Loss:  1788.6819 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  54 -Loss:  1268.6263 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  55 -Loss:  1217.5477 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  56 -Loss:  1589.1284 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  57 -Loss:  1431.1069 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  58 -Loss:  1556.3353 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  59 -Loss:  1524.0719 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  60 -Loss:  1535.4066 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  61 -Loss:  1605.9387 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  62 -Loss:  1349.9794 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  63 -Loss:  1546.4580 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  64 -Loss:  1471.6180 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  65 -Loss:  1051.4561 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  66 -Loss:  1480.2983 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  67 -Loss:  1206.8193 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  68 -Loss:  1476.9064 Validation Accuracy: 0.687500\n",
      "Epoch  2, Batch  69 -Loss:  1648.9644 Validation Accuracy: 0.687500\n",
      "Epoch  2, Batch  70 -Loss:  1820.5970 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  71 -Loss:  1250.9341 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  72 -Loss:  1283.4181 Validation Accuracy: 0.687500\n",
      "Epoch  2, Batch  73 -Loss:  1517.1112 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  74 -Loss:  1455.9839 Validation Accuracy: 0.675781\n",
      "Epoch  2, Batch  75 -Loss:  2057.6565 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  76 -Loss:  1347.4287 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  77 -Loss:  1374.8956 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  78 -Loss:  2097.8250 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  79 -Loss:  1712.2592 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  80 -Loss:  1643.8330 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  81 -Loss:   672.2761 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  82 -Loss:  1369.2981 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  83 -Loss:  1962.8314 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  84 -Loss:  1166.2063 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  85 -Loss:   943.7940 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch  86 -Loss:  1464.5815 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  87 -Loss:  1594.2090 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  88 -Loss:  1752.6541 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  89 -Loss:  1131.4159 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  90 -Loss:  1509.1316 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  91 -Loss:  1550.9562 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  92 -Loss:  1334.2026 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch  93 -Loss:  1132.4575 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  94 -Loss:  1824.0295 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  95 -Loss:  1604.1309 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch  96 -Loss:  1707.1709 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  97 -Loss:  1605.5817 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  98 -Loss:  1114.2520 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  99 -Loss:  1325.8093 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 100 -Loss:  1491.0631 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 101 -Loss:  1013.5291 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 102 -Loss:   882.2274 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 103 -Loss:  1013.8684 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 104 -Loss:  1161.1938 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 105 -Loss:  1283.0549 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 106 -Loss:   845.8595 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 107 -Loss:  1101.2144 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 108 -Loss:  1206.6511 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 109 -Loss:  1227.8362 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 110 -Loss:   935.2195 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 111 -Loss:  1902.1428 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 112 -Loss:  1059.4819 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 113 -Loss:   958.9528 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 114 -Loss:  1296.0366 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 115 -Loss:  1405.9814 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 116 -Loss:  1391.7019 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 117 -Loss:  1546.6863 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 118 -Loss:  1077.7705 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 119 -Loss:  1331.7148 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 120 -Loss:  1300.0411 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 121 -Loss:  1263.5404 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 122 -Loss:  1347.2926 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 123 -Loss:  1429.8853 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 124 -Loss:  1552.3372 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 125 -Loss:  1299.8479 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 126 -Loss:  1600.8071 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 127 -Loss:  1184.2156 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 128 -Loss:  1171.7269 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 129 -Loss:  1333.4038 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 130 -Loss:  1010.9159 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 131 -Loss:  1439.7318 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 132 -Loss:  1137.5632 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 133 -Loss:  1201.1641 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 134 -Loss:   941.3221 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 135 -Loss:  1335.8134 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 136 -Loss:  1799.9880 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 137 -Loss:  1068.6685 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 138 -Loss:  1518.8052 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 139 -Loss:  1196.9419 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 140 -Loss:  1488.8765 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 141 -Loss:  1280.3877 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 142 -Loss:   699.5190 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 143 -Loss:  1054.4456 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 144 -Loss:   860.3209 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 145 -Loss:  1277.4836 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 146 -Loss:  1189.1573 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 147 -Loss:  1373.7200 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 148 -Loss:  1296.3965 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 149 -Loss:  1141.2251 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 150 -Loss:  1065.5908 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 151 -Loss:  1154.4915 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 152 -Loss:  1460.7356 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 153 -Loss:   641.1323 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 154 -Loss:  1267.9619 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 155 -Loss:  1057.8513 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 156 -Loss:  1346.0364 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 157 -Loss:  1265.0292 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 158 -Loss:  1373.0845 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 159 -Loss:  1312.1306 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 160 -Loss:   876.5621 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 161 -Loss:  1305.6639 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 162 -Loss:  1012.0038 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 163 -Loss:  1321.2491 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 164 -Loss:   769.0183 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 165 -Loss:   999.6458 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 166 -Loss:  1229.8105 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 167 -Loss:  1021.8493 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 168 -Loss:  1230.4420 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 169 -Loss:   799.8519 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 170 -Loss:  1011.8921 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 171 -Loss:   983.5145 Validation Accuracy: 0.730469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 172 -Loss:  1018.7261 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 173 -Loss:  1211.0481 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 174 -Loss:  1398.0199 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 175 -Loss:   873.7899 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 176 -Loss:  1178.8821 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 177 -Loss:   848.8541 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 178 -Loss:  1270.1240 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 179 -Loss:  1162.3120 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 180 -Loss:  1329.0664 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 181 -Loss:   781.3706 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 182 -Loss:   953.5500 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 183 -Loss:  1210.9108 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 184 -Loss:   997.6331 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 185 -Loss:  1266.0063 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 186 -Loss:  1056.1874 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 187 -Loss:  1184.8635 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 188 -Loss:   571.3940 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 189 -Loss:  1162.6555 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 190 -Loss:  1246.4258 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 191 -Loss:   846.5220 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 192 -Loss:   961.3647 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 193 -Loss:   786.0156 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 194 -Loss:  1096.1107 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 195 -Loss:  1379.3328 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 196 -Loss:  1138.7124 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 197 -Loss:  1129.8364 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 198 -Loss:  1064.0662 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 199 -Loss:  1178.9696 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 200 -Loss:  1614.5254 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 201 -Loss:  1184.5762 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 202 -Loss:  1584.9817 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 203 -Loss:  1220.3868 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 204 -Loss:   859.4302 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 205 -Loss:   890.1722 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 206 -Loss:  1123.0757 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 207 -Loss:  1645.7361 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 208 -Loss:   748.1204 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 209 -Loss:  1122.4337 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 210 -Loss:  1227.5540 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 211 -Loss:  1163.6364 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 212 -Loss:  1224.0752 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 213 -Loss:  1768.7386 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 214 -Loss:  1431.4574 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 215 -Loss:  1484.6532 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 216 -Loss:  1114.9413 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 217 -Loss:   961.3036 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 218 -Loss:  1305.8901 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 219 -Loss:  1200.2002 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 220 -Loss:  1153.6761 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 221 -Loss:  1133.9513 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 222 -Loss:  1435.0632 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 223 -Loss:  1171.1763 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 224 -Loss:  1179.5546 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 225 -Loss:   991.6130 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 226 -Loss:  1553.5254 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 227 -Loss:   897.9133 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 228 -Loss:  1505.5045 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 229 -Loss:   784.6445 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 230 -Loss:  1412.9988 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 231 -Loss:   703.9850 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 232 -Loss:  1215.5775 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 233 -Loss:   905.2562 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 234 -Loss:   709.6067 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 235 -Loss:  1220.6528 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 236 -Loss:  1152.5665 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 237 -Loss:   893.7025 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 238 -Loss:   962.6506 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 239 -Loss:   674.4824 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 240 -Loss:  1114.6290 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 241 -Loss:  1036.8708 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 242 -Loss:  1272.8009 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 243 -Loss:  1544.4254 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 244 -Loss:  1521.7942 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 245 -Loss:   984.0280 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 246 -Loss:   871.4671 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 247 -Loss:   783.5690 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 248 -Loss:  1288.7969 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 249 -Loss:  1355.3228 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 250 -Loss:  1109.9578 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 251 -Loss:  1150.9150 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 252 -Loss:   958.7242 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 253 -Loss:  1145.9031 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 254 -Loss:  1092.0087 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 255 -Loss:  1421.1233 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 256 -Loss:   765.4509 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 257 -Loss:   931.4637 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 258 -Loss:   703.2439 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 259 -Loss:   874.4603 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 260 -Loss:  1140.2290 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 261 -Loss:  1380.6322 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 262 -Loss:  1288.6537 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 263 -Loss:  1049.8501 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 264 -Loss:   986.3817 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 265 -Loss:  1193.1060 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 266 -Loss:  1245.3881 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 267 -Loss:  1408.7744 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 268 -Loss:  1101.9939 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 269 -Loss:   967.2728 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 270 -Loss:   847.1454 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 271 -Loss:  1168.1577 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 272 -Loss:  1039.6697 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 273 -Loss:   825.8024 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 274 -Loss:  1062.0822 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 275 -Loss:  1107.6453 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 276 -Loss:   998.7413 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 277 -Loss:  1169.7063 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 278 -Loss:  1134.8413 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 279 -Loss:   811.7452 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 280 -Loss:  1040.4225 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 281 -Loss:  1170.3733 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 282 -Loss:   918.7820 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 283 -Loss:   885.4550 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 284 -Loss:  1256.4258 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 285 -Loss:   910.8957 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 286 -Loss:  1069.4097 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 287 -Loss:  1252.7378 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 288 -Loss:   769.5016 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 289 -Loss:  1155.2754 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 290 -Loss:   617.5756 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 291 -Loss:   628.7016 Validation Accuracy: 0.742188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 292 -Loss:   876.8788 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 293 -Loss:  1274.2283 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 294 -Loss:   870.7592 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 295 -Loss:   899.9937 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 296 -Loss:  1187.4712 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 297 -Loss:  1020.0690 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 298 -Loss:  1238.0549 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 299 -Loss:  1419.8859 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 300 -Loss:   986.7589 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 301 -Loss:  1039.2891 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 302 -Loss:  1405.8390 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 303 -Loss:   916.4078 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 304 -Loss:   711.5842 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 305 -Loss:   913.0569 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 306 -Loss:   707.6837 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 307 -Loss:   648.4659 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 308 -Loss:   889.5856 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 309 -Loss:  1368.3851 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 310 -Loss:   877.2517 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 311 -Loss:  1011.9196 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 312 -Loss:  1364.4429 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 313 -Loss:   827.1398 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 314 -Loss:  1155.9163 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 315 -Loss:  1001.3973 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 316 -Loss:   912.3637 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 317 -Loss:   830.0024 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 318 -Loss:   784.6518 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 319 -Loss:  1107.0850 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 320 -Loss:  1091.2148 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 321 -Loss:   662.6053 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 322 -Loss:   710.7411 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 323 -Loss:   753.7837 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 324 -Loss:  1135.7668 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 325 -Loss:   777.0848 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 326 -Loss:  1053.7374 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 327 -Loss:  1088.0920 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 328 -Loss:   702.2190 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 329 -Loss:  1256.7812 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 330 -Loss:   904.4630 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 331 -Loss:  1320.2523 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 332 -Loss:  1013.6258 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 333 -Loss:  1078.3289 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 334 -Loss:   903.7045 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 335 -Loss:   975.8274 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 336 -Loss:   947.4909 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 337 -Loss:   888.6224 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 338 -Loss:  1069.7651 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 339 -Loss:  1131.5433 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 340 -Loss:   979.6863 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 341 -Loss:  1091.7444 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 342 -Loss:  1118.9299 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 343 -Loss:   723.3369 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 344 -Loss:   997.0917 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 345 -Loss:  1010.1605 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 346 -Loss:   770.0441 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 347 -Loss:  1090.4626 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 348 -Loss:   871.6117 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 349 -Loss:  1112.4026 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 350 -Loss:   988.6364 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 351 -Loss:  1163.4086 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 352 -Loss:   883.2068 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 353 -Loss:   659.6174 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 354 -Loss:   600.9203 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 355 -Loss:   930.0089 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 356 -Loss:   961.9672 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 357 -Loss:  1053.3318 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 358 -Loss:  1040.5039 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 359 -Loss:  1152.5172 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 360 -Loss:  1002.6232 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 361 -Loss:  1149.5599 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 362 -Loss:  1123.0221 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 363 -Loss:   933.6132 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 364 -Loss:   781.9476 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 365 -Loss:  1021.5148 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 366 -Loss:  1303.6221 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 367 -Loss:  1027.1674 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 368 -Loss:   750.3608 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 369 -Loss:   826.1000 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 370 -Loss:   947.1213 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 371 -Loss:  1126.5419 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 372 -Loss:   781.2439 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 373 -Loss:   882.5433 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 374 -Loss:   882.1503 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 375 -Loss:   850.0232 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 376 -Loss:   816.9943 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 377 -Loss:   925.8171 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 378 -Loss:  1048.6421 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 379 -Loss:   793.8015 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 380 -Loss:   641.0499 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 381 -Loss:   826.7053 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 382 -Loss:   692.3934 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 383 -Loss:  1276.4177 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 384 -Loss:   569.9194 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 385 -Loss:  1238.6143 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 386 -Loss:   848.6552 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 387 -Loss:   997.1247 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 388 -Loss:   882.8591 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 389 -Loss:  1090.6378 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 390 -Loss:   784.2411 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 391 -Loss:   813.0927 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 392 -Loss:   914.3654 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 393 -Loss:  1081.4197 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 394 -Loss:   998.3851 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 395 -Loss:   660.7295 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 396 -Loss:   907.8859 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 397 -Loss:   706.0565 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 398 -Loss:   811.8585 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 399 -Loss:   934.8647 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 400 -Loss:  1016.9769 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 401 -Loss:   926.3704 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 402 -Loss:   937.0562 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 403 -Loss:   893.2729 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 404 -Loss:   804.0994 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 405 -Loss:   921.0946 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 406 -Loss:   949.6767 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 407 -Loss:   812.1432 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 408 -Loss:   550.3312 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 409 -Loss:   958.2455 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 410 -Loss:   835.5521 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 411 -Loss:   774.9135 Validation Accuracy: 0.753906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 412 -Loss:   851.0692 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 413 -Loss:   930.7715 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 414 -Loss:   880.6614 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 415 -Loss:  1121.4854 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 416 -Loss:   979.8308 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 417 -Loss:   823.8632 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 418 -Loss:  1219.6870 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 419 -Loss:   841.4670 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 420 -Loss:   882.7383 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 421 -Loss:   584.5535 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 422 -Loss:   580.5248 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 423 -Loss:   777.5316 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 424 -Loss:   874.0952 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 425 -Loss:   865.2236 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 426 -Loss:  1076.5538 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 427 -Loss:   676.8065 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 428 -Loss:   702.7399 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 429 -Loss:   964.5781 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch   1 -Loss:  1009.6478 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch   2 -Loss:  1227.3301 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch   3 -Loss:   871.8929 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch   4 -Loss:   872.5054 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch   5 -Loss:  1135.8748 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch   6 -Loss:   733.1405 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch   7 -Loss:  1055.9117 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch   8 -Loss:   746.0342 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch   9 -Loss:   497.3789 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  10 -Loss:   654.8219 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  11 -Loss:  1119.2765 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  12 -Loss:  1061.0361 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  13 -Loss:   957.2805 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  14 -Loss:   712.7746 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  15 -Loss:   932.3658 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  16 -Loss:   802.5167 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  17 -Loss:   783.2710 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  18 -Loss:   744.0832 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  19 -Loss:   471.7377 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  20 -Loss:   864.9575 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  21 -Loss:   990.4999 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  22 -Loss:   967.4833 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  23 -Loss:   994.7874 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  24 -Loss:   947.7131 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  25 -Loss:  1228.4918 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  26 -Loss:   695.3870 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  27 -Loss:   972.0020 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  28 -Loss:  1047.2295 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  29 -Loss:  1208.0425 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  30 -Loss:   674.6685 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  31 -Loss:   783.1321 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  32 -Loss:   638.5274 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  33 -Loss:   992.8076 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  34 -Loss:   422.3669 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  35 -Loss:   738.2682 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  36 -Loss:   847.5098 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  37 -Loss:   837.3794 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  38 -Loss:   802.5062 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  39 -Loss:   852.9940 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  40 -Loss:   860.3359 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  41 -Loss:   762.1244 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch  42 -Loss:  1032.5332 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch  43 -Loss:  1028.6238 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch  44 -Loss:   656.5140 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  45 -Loss:   912.4425 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  46 -Loss:   845.5753 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  47 -Loss:  1061.3633 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  48 -Loss:   800.8732 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  49 -Loss:   897.4778 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  50 -Loss:   609.6464 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  51 -Loss:   959.4778 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  52 -Loss:   861.2971 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  53 -Loss:   682.6462 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch  54 -Loss:   901.5568 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  55 -Loss:   664.6929 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  56 -Loss:   995.9229 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  57 -Loss:   720.0143 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  58 -Loss:   856.6288 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  59 -Loss:   759.5258 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  60 -Loss:  1129.5024 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  61 -Loss:   653.1447 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  62 -Loss:   856.0145 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  63 -Loss:   804.3217 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  64 -Loss:   725.7228 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  65 -Loss:   932.6666 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  66 -Loss:   961.1212 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  67 -Loss:   823.6159 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  68 -Loss:   914.9930 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  69 -Loss:  1170.5991 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  70 -Loss:   652.1594 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  71 -Loss:   949.5055 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  72 -Loss:  1065.1383 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  73 -Loss:   520.3429 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  74 -Loss:  1239.5432 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  75 -Loss:   851.7926 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  76 -Loss:  1130.9158 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  77 -Loss:   837.7358 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  78 -Loss:   958.8195 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  79 -Loss:   838.1641 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch  80 -Loss:   922.0864 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch  81 -Loss:   595.5007 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  82 -Loss:   784.6136 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch  83 -Loss:   543.9064 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  84 -Loss:   426.7712 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  85 -Loss:  1036.0012 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  86 -Loss:   797.4133 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch  87 -Loss:   723.5723 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  88 -Loss:   919.9915 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch  89 -Loss:  1315.9604 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch  90 -Loss:   512.7278 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  91 -Loss:   877.1381 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch  92 -Loss:   677.0645 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  93 -Loss:   792.4907 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  94 -Loss:   969.1753 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  95 -Loss:   729.4883 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  96 -Loss:   887.8895 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  97 -Loss:   782.6851 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  98 -Loss:   844.0686 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  99 -Loss:   994.9332 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 100 -Loss:   930.8217 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 101 -Loss:   818.6722 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 102 -Loss:  1014.3309 Validation Accuracy: 0.785156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3, Batch 103 -Loss:   610.6558 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 104 -Loss:   587.7841 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 105 -Loss:   816.5408 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 106 -Loss:  1046.8079 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 107 -Loss:  1083.0857 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 108 -Loss:   636.7065 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 109 -Loss:   796.2322 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 110 -Loss:   814.1167 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 111 -Loss:   939.5027 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 112 -Loss:   785.9685 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 113 -Loss:   839.5512 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 114 -Loss:   461.3395 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 115 -Loss:   863.3888 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 116 -Loss:   945.4983 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 117 -Loss:   928.5607 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 118 -Loss:   831.2372 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 119 -Loss:   404.4301 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 120 -Loss:   797.9115 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 121 -Loss:   527.7892 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 122 -Loss:   509.7501 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 123 -Loss:   647.6989 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 124 -Loss:   752.1522 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 125 -Loss:   774.4705 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 126 -Loss:   794.6628 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 127 -Loss:   929.4717 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 128 -Loss:   793.6079 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 129 -Loss:   686.0532 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 130 -Loss:   801.6885 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 131 -Loss:   811.7673 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 132 -Loss:   920.0868 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 133 -Loss:   914.4606 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 134 -Loss:   749.4277 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 135 -Loss:   637.2667 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 136 -Loss:   607.2133 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 137 -Loss:  1282.5510 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 138 -Loss:   808.8423 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 139 -Loss:   831.9564 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 140 -Loss:   893.2241 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 141 -Loss:   774.8046 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 142 -Loss:   736.7756 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 143 -Loss:   551.0034 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 144 -Loss:   730.9341 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 145 -Loss:   561.9875 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 146 -Loss:   703.3741 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 147 -Loss:   667.1632 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 148 -Loss:   740.0651 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 149 -Loss:   959.8151 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 150 -Loss:  1107.0935 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 151 -Loss:   813.2527 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 152 -Loss:   861.3411 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 153 -Loss:   881.8915 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 154 -Loss:   790.2877 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 155 -Loss:   802.7333 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 156 -Loss:   673.3283 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 157 -Loss:   669.9682 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 158 -Loss:   853.3417 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 159 -Loss:   621.0994 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 160 -Loss:   614.9822 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 161 -Loss:   811.1821 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 162 -Loss:   805.4202 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 163 -Loss:  1090.8922 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 164 -Loss:   781.2380 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 165 -Loss:   898.6652 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 166 -Loss:   759.0974 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 167 -Loss:   936.2103 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 168 -Loss:   621.6722 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 169 -Loss:   882.5194 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 170 -Loss:   655.1477 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 171 -Loss:   866.5779 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 172 -Loss:   813.1202 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 173 -Loss:   636.7468 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 174 -Loss:   833.3093 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 175 -Loss:   802.2124 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 176 -Loss:   622.3782 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 177 -Loss:   851.2195 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 178 -Loss:   611.8904 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 179 -Loss:   969.5559 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 180 -Loss:   928.1426 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 181 -Loss:   717.6304 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 182 -Loss:   616.0243 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 183 -Loss:   751.9557 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 184 -Loss:   611.9472 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 185 -Loss:   619.5508 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 186 -Loss:   718.7706 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 187 -Loss:   612.5848 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 188 -Loss:   782.8127 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 189 -Loss:   746.3021 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 190 -Loss:   745.5189 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 191 -Loss:   961.9007 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 192 -Loss:   924.6999 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 193 -Loss:   744.3749 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 194 -Loss:   864.9524 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 195 -Loss:   524.7001 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 196 -Loss:   872.6654 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 197 -Loss:   981.1151 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 198 -Loss:   921.5587 Validation Accuracy: 0.796875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a0a709d70f6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 keep_prob: dropout})\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;31m# Calculate batch loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\image\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\image\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\image\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\image\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\image\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf. global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} -'\n",
    "                  'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
